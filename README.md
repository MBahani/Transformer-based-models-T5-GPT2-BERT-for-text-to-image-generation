# Text-to-Image Generation Comparative Study

This repository contains code for a research project titled "The effectiveness of T5, GPT-2, and BERT on text-to-image generation task". The project investigates the performance of T5, GPT-2, and BERT models in generating images from textual descriptions, using deep learning techniques.


## Citation

If you find this work helpful in your research, please consider citing the following article:

```
@article{BAHANI202357,
title = {The effectiveness of T5, GPT-2, and BERT on text-to-image generation task},
journal = {Pattern Recognition Letters},
volume = {173},
pages = {57-63},
year = {2023},
issn = {0167-8655},
doi = {https://doi.org/10.1016/j.patrec.2023.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0167865523002210},
author = {Mourad Bahani and Aziza El Ouaazizi and Khalil Maalmi},
keywords = {Deep learning, Computer vision, Generative adversarial networks, Text-to-image generation, Natural language processing, Transformer-based models},
}
```

## Description

This project explores the capabilities of transformer-based models - T5, GPT-2, and BERT - in the context of text-to-image generation. It proposes three architectures to conduct a comparative study of these models and fine-tunes them to generate text vectors. These vectors are then transformed into images using the affine transformation into the DF-GAN generator.

## Data

Experiments are conducted on the CUB and Oxford-102 flower datasets, which are widely used benchmarks for image generation tasks.

## Results

Our experiments demonstrate that T5 exhibits promising potential for text-to-image generation tasks. It shows the capability to generate visually appealing and semantically coherent images from textual descriptions.

## Usage

Please find the instructions on the BERT notebook



Thank you for your interest in our research!
